{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larsmoan/COMP3710/blob/main/assignement_2/cnn/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XR1_XH9ZiwkS"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/UQ/COMP3710/COMP3710/.venv/lib/python3.11/site-packages/torchvision/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def show_pic_tensor(img_tensor):\n",
        "  image_np = img_tensor.numpy()\n",
        "  # Display the grayscale image in black and white\n",
        "  plt.imshow(image_np, cmap='gray', vmin=0, vmax=1)  # Use the 'gray' colormap\n",
        "  plt.axis('off')  # Turn off axis labels and ticks\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppTBgy4LuS03",
        "outputId": "3f8aa333-51c9-44e7-b131-1dcc05d706af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (973, 1, 50, 37)\n"
          ]
        }
      ],
      "source": [
        "# Fetch the LFW dataset\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "n_classes = lfw_people.target_names.shape[0]\n",
        "\n",
        "# Convert images to grayscale\n",
        "X_gray = [Image.fromarray(image).convert('L') for image in lfw_people.images]\n",
        "\n",
        "X = lfw_people.images\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, lfw_people.target, test_size=0.2, random_state=42)\n",
        "X_train = X_train[:, np.newaxis, :, :]\n",
        "X_test = X_test[:, np.newaxis, :, :]\n",
        "print(\"X_train shape:\", X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0nEHXBZtnDqt"
      },
      "outputs": [],
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_train = torch.from_numpy(y_train)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "\n",
        "# Create TensorDatasets for train and test data\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define batch size for the data loaders\n",
        "batch_size = 6\n",
        "\n",
        "# Create DataLoader instances for train and test data\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xb9eDX3divSZ"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Changed input channels to 1\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Added another convolutional layer\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 12 * 9, 128),  # Adjusted input size\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq25ogpXtDle",
        "outputId": "c665249c-3eea-40e5-8439-20d2e98db91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 1.3914501076004258\n",
            "Epoch 2/10, Loss: 0.6414667014761091\n",
            "Epoch 3/10, Loss: 0.37944710778038193\n",
            "Epoch 4/10, Loss: 0.24164765219056286\n",
            "Epoch 5/10, Loss: 0.13312485561737106\n",
            "Epoch 6/10, Loss: 0.046329849591613334\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNClassifier(num_classes=n_classes).to(device)\n",
        "\n",
        "# Define the loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi-kmyHZv5ag",
        "outputId": "e4643ce2-1001-4485-e28c-c8966078d8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 91.86046511627907%\n"
          ]
        }
      ],
      "source": [
        "# Test loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnuDrkf_pLg_"
      },
      "outputs": [],
      "source": [
        "#Save the weights to a .pt file\n",
        "weights_path = \"lfw_faces.pt\"\n",
        "torch.save(model.state_dict(), weights_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPVAa5SvwA73nadqb46oc7+",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
